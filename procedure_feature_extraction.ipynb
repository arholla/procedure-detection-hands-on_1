{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('procedure_det': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4d83f2824dc1cb43aeaedf9feae7e4887829005d749a2c755ba5d31b1bd5b2cf"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Feature Extraction\n",
    "\n",
    "Now that we know that the sentences in procedures are imperatives, have verbs in the form of infinitives and gerunds; let's derive features that characterize them."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data'\n",
    "train_df = pd.read_csv(os.path.join(DATA_PATH, 'procedure_train_data.csv'), encoding='utf-8')\n",
    "test_df = pd.read_csv(os.path.join(DATA_PATH, 'procedure_train_data.csv'), encoding='utf-8')"
   ]
  },
  {
   "source": [
    "## Example for an imperative"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "choose choose VERB VB 14200088355797579614 ROOT xxxx True False\ntools tool NOUN NNS 783433942507015291 compound xxxx True False\n- - PUNCT HYPH 8214596291009089021 punct - False False\nautocorrect autocorrect NOUN NN 15308085513773655218 dobj xxxx True False\n, , PUNCT , 2593208677638477497 punct , False False\nand and CCONJ CC 17571114184892886314 cc xxx True True\nensure ensure VERB VB 14200088355797579614 conj xxxx True False\nthat that SCONJ IN 1292078113972184607 mark xxxx True True\nwhile while SCONJ IN 1292078113972184607 mark xxxx True True\ntyping typing NOUN NN 15308085513773655218 nsubjpass xxxx True False\nis be AUX VBZ 13927759927860985106 auxpass xx True True\nselected select VERB VBN 3822385049556375858 ccomp xxxx True False\n. . PUNCT . 12646065887601541794 punct . False False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"choose tools - autocorrect , and ensure that while typing is selected.\")\n",
    "\n",
    "for token in doc:\n",
    "    print (token.text, token.lemma_, token.pos_, token.tag_, token.tag, token.dep_, token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "source": [
    "## Example for an infinitive"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "to to PART TO 5595707737748328492 aux xx True True\nonly only ADV RB 164681854541413346 advmod xxxx True True\napply apply VERB VB 14200088355797579614 advcl xxxx True False\nthe the DET DT 15267657372422890137 det xxx True True\nnew new ADJ JJ 10554686591937588953 amod xxx True False\npage page NOUN NN 15308085513773655218 compound xxxx True False\nstyle style NOUN NN 15308085513773655218 dobj xxxx True False\nto to ADP IN 1292078113972184607 prep xx True True\na a DET DT 15267657372422890137 det x True True\nsingle single ADJ JJ 10554686591937588953 amod xxxx True False\npage page NOUN NN 15308085513773655218 pobj xxxx True False\n, , PUNCT , 2593208677638477497 punct , False False\nselect select VERB VB 14200088355797579614 ROOT xxxx True False\ndefault default NOUN NN 15308085513773655218 dobj xxxx True False\n. . PUNCT . 12646065887601541794 punct . False False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"to only apply the new page style to a single page, select default.\")\n",
    "\n",
    "for token in doc:\n",
    "    print (token.text, token.lemma_, token.pos_, token.tag_, token.tag, token.dep_, token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "source": [
    "## Example of a gerund"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "double double ADJ JJ 10554686591937588953 amod xxxx True False\n- - PUNCT HYPH 8214596291009089021 punct - False False\nclick click NOUN NN 15308085513773655218 ROOT xxxx True False\non on ADP IN 1292078113972184607 prep xx True True\nan an DET DT 15267657372422890137 det xx True True\nexisting exist VERB VBG 1534113631682161808 amod xxxx True False\ntitle title NOUN NN 15308085513773655218 compound xxxx True False\ntext text NOUN NN 15308085513773655218 pobj xxxx True False\n. . PUNCT . 12646065887601541794 punct . False False\n******************************\nto to PART TO 5595707737748328492 aux xx True True\nremove remove VERB VB 14200088355797579614 advcl xxxx True False\nthe the DET DT 15267657372422890137 det xxx True True\nnumber number NOUN NN 15308085513773655218 dobj xxxx True False\nand and CCONJ CC 17571114184892886314 cc xxx True True\nthe the DET DT 15267657372422890137 det xxx True True\nindent indent NOUN NN 15308085513773655218 conj xxxx True False\nof of ADP IN 1292078113972184607 prep xx True True\nthe the DET DT 15267657372422890137 det xxx True True\nparagraph paragraph NOUN NN 15308085513773655218 pobj xxxx True False\n, , PUNCT , 2593208677638477497 punct , False False\nclick click VERB VB 14200088355797579614 ROOT xxxx True False\nthe the DET DT 15267657372422890137 det xxx True True\nnumbering number VERB VBG 1534113631682161808 amod xxxx True False\nonoff onoff PROPN NNP 15794550382381185553 compound xxxx True False\nicon icon NOUN NN 15308085513773655218 dobj xxxx True False\non on ADP IN 1292078113972184607 prep xx True True\nthe the DET DT 15267657372422890137 det xxx True True\nformatting formatting NOUN NN 15308085513773655218 amod xxxx True False\nbar bar NOUN NN 15308085513773655218 pobj xxx True False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"double-click on an existing title text.\")\n",
    "\n",
    "for token in doc:\n",
    "    print (token.text, token.lemma_, token.pos_, token.tag_, token.tag, token.dep_, token.shape_, token.is_alpha, token.is_stop)\n",
    "print ('*'*30)\n",
    "\n",
    "doc = nlp(\"to remove the number and the indent of the paragraph, click the numbering onoff icon on the formatting bar\")\n",
    "\n",
    "for token in doc:\n",
    "    print (token.text, token.lemma_, token.pos_, token.tag_, token.tag, token.dep_, token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "source": [
    "Let's extract the features which are unique to imperatives and infinitives\n",
    "- Number of sentences starting with a verb\n",
    "- Number of sentences without a subject\n",
    "- Number of infinitive verbs\n",
    "- Number of gerunds\n",
    "\n",
    "- Average length of steps in a procedure"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import nsubj, VERB, PART\n",
    "from ast import literal_eval\n",
    "from spacy.attrs import DEP, POS, LENGTH, TAG\n",
    "TO = 5595707737748328492 #infinitive to id \n",
    "VBG = 1534113631682161808 #gerund id"
   ]
  },
  {
   "source": [
    "Each procedure/non-procedure is contains text of instructions/steps separated by a delimiter ' <st\\> '. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'choose view - styles . <st> click the page styles icon. <st> right-click a page style and choose new . the new page style initially gets all properties of the selected page style. <st> on the organizer tab page, type a name for the page style in the name box, for example \"my landscape\". <st> in the next style box, select the page style that you want to apply to the next page that follows a page with the new style. see the section about the scope of page styles at the end of this help page. <st> click the page tab. <st> under paper format , select \\'portrait\\' or \\'landscape\\'. <st> click ok .'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train_df['Lists'][0]"
   ]
  },
  {
   "source": [
    "Let's split them to extract each step into a list. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['choose view - styles .',\n",
       " 'click the page styles icon.',\n",
       " 'right-click a page style and choose new . the new page style initially gets all properties of the selected page style.',\n",
       " 'on the organizer tab page, type a name for the page style in the name box, for example \"my landscape\".',\n",
       " 'in the next style box, select the page style that you want to apply to the next page that follows a page with the new style. see the section about the scope of page styles at the end of this help page.',\n",
       " 'click the page tab.',\n",
       " \"under paper format , select 'portrait' or 'landscape'.\",\n",
       " 'click ok .']"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "train_lists = train_df['Lists'].apply(lambda x:x.split(' <st> ')).tolist()\n",
    "test_lists = train_df['Lists'].apply(lambda x:x.split(' <st> ')).tolist()\n",
    "train_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_verb = []\n",
    "list_subj = []\n",
    "list_gerund = []\n",
    "list_infinitive = []\n",
    "avg_len = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for li in train_lists:\n",
    "    doc_arrays = [doc.to_array([DEP, POS, TAG]) for doc in map(nlp, li)]\n",
    "    list_subj.append(sum(nsubj not in doc_array[:,0] and doc_array.shape[0]>2 for doc_array in doc_arrays))\n",
    "    list_verb.append(sum(VERB == doc_array[0,1] and doc_array.shape[0]>1 for doc_array in doc_arrays))\n",
    "    list_gerund.append(sum(VBG in doc_array[:,2] and VERB in doc_array[:,1] for doc_array in doc_arrays))\n",
    "    list_infinitive.append(sum(TO in doc_array[:,2] and PART in doc_array[:,1] for doc_array in doc_arrays))\n",
    "    avg_len.append(sum(list(map(lambda x:x.shape[0], doc_arrays)))/len(li))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"Lists\":train_df['Lists'], \"Sents-No Subject\":list_subj, \"Sents-Starts with Verb\":list_verb, \"Avg Length\":avg_len, \"Gerunds\": list_gerund, \"Infinitives\": list_infinitive, \"Labels\": train_df['Labels']}) \n",
    "df1.to_csv(os.path.join(DATA_PATH, \"dense_features_train_procedures.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_verb = []\n",
    "list_subj = []\n",
    "list_gerund = []\n",
    "list_infinitive = []\n",
    "avg_len = []\n",
    "for li in test_lists:\n",
    "    doc_arrays = [doc.to_array([DEP, POS, TAG]) for doc in map(nlp, li)]\n",
    "    list_subj.append(sum(nsubj not in doc_array[:,0] and doc_array.shape[0]>2 for doc_array in doc_arrays))\n",
    "    list_verb.append(sum(VERB == doc_array[0,1] and doc_array.shape[0]>1 for doc_array in doc_arrays))\n",
    "    list_gerund.append(sum(VBG in doc_array[:,2] and VERB in doc_array[:,1] for doc_array in doc_arrays))\n",
    "    list_infinitive.append(sum(TO in doc_array[:,2] and PART in doc_array[:,1] for doc_array in doc_arrays))\n",
    "    avg_len.append(sum(list(map(lambda x:x.shape[0], doc_arrays)))/len(li))\n",
    "\n",
    "df1 = pd.DataFrame({\"Lists\":test_df['Lists'], \"Sents-No Subject\":list_subj, \"Sents-Starts with Verb\":list_verb, \"Avg Length\":avg_len, \"Gerunds\": list_gerund, \"Infinitives\": list_infinitive, \"Labels\": test_df['Labels']}) \n",
    "df1.to_csv(os.path.join(DATA_PATH, \"dense_features_test_procedures.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}